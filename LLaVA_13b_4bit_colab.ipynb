{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aosm26/Aosm26/blob/main/LLaVA_13b_4bit_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/haotian-liu/LLaVA.git\n",
        "\n",
        "%cd /content/LLaVA\n",
        "\n",
        "!pip install --upgrade pip\n",
        "!pip install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cyNFCz5JMGOV",
        "outputId": "b1447871-5770-4e4d-9fdd-d805c4c66141"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'LLaVA'...\n",
            "remote: Enumerating objects: 2297, done.\u001b[K\n",
            "remote: Total 2297 (delta 0), reused 0 (delta 0), pack-reused 2297 (from 1)\u001b[K\n",
            "Receiving objects: 100% (2297/2297), 13.71 MiB | 27.58 MiB/s, done.\n",
            "Resolving deltas: 100% (1404/1404), done.\n",
            "/content/LLaVA\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.0.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Downloading pip-25.0.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/commands/install.py\", line 455, in run\n",
            "    installed = install_given_reqs(\n",
            "                ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/req/__init__.py\", line 65, in install_given_reqs\n",
            "    uninstalled_pathset = requirement.uninstall(auto_confirm=True)\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/req/req_install.py\", line 715, in uninstall\n",
            "    dist = get_default_environment().get_distribution(self.req.name)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/metadata/importlib/_envs.py\", line 189, in get_distribution\n",
            "    return next(matches, None)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/metadata/importlib/_envs.py\", line 184, in <genexpr>\n",
            "    matches = (\n",
            "              ^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/metadata/base.py\", line 612, in iter_all_distributions\n",
            "    for dist in self._iter_distributions():\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/metadata/importlib/_envs.py\", line 176, in _iter_distributions\n",
            "    yield from finder.find(location)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/metadata/importlib/_envs.py\", line 79, in find\n",
            "    for dist, info_location in self._find_impl(location):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/metadata/importlib/_envs.py\", line 64, in _find_impl\n",
            "    raw_name = get_dist_name(dist)\n",
            "               ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/metadata/importlib/_compat.py\", line 52, in get_dist_name\n",
            "    name = cast(Any, dist).name\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/importlib/metadata/__init__.py\", line 622, in name\n",
            "    return self.metadata['Name']\n",
            "           ^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/importlib/metadata/__init__.py\", line 617, in metadata\n",
            "    return _adapters.Message(email.message_from_string(text))\n",
            "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/email/__init__.py\", line 37, in message_from_string\n",
            "    return Parser(*args, **kws).parsestr(s)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/email/parser.py\", line 67, in parsestr\n",
            "    return self.parse(StringIO(text), headersonly=headersonly)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/email/parser.py\", line 56, in parse\n",
            "    feedparser.feed(data)\n",
            "  File \"/usr/lib/python3.11/email/feedparser.py\", line 174, in feed\n",
            "    self._call_parse()\n",
            "  File \"/usr/lib/python3.11/email/feedparser.py\", line 178, in _call_parse\n",
            "    self._parse()\n",
            "  File \"/usr/lib/python3.11/email/feedparser.py\", line 226, in _parsegen\n",
            "    if not headerRE.match(line):\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n",
            "    return command.main(cmd_args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n",
            "    return self._main(args)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n",
            "    return run(options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 215, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1536, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1634, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1644, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line -1, in callHandlers\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.8/126.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m97.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 3.4.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.36.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mObtaining file:///content/LLaVA\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch==2.1.2 (from llava==1.2.2.post1)\n",
            "  Downloading torch-2.1.2-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Collecting torchvision==0.16.2 (from llava==1.2.2.post1)\n",
            "  Downloading torchvision-0.16.2-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting transformers==4.37.2 (from llava==1.2.2.post1)\n",
            "  Downloading transformers-4.37.2-py3-none-any.whl.metadata (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers==0.15.1 (from llava==1.2.2.post1)\n",
            "  Downloading tokenizers-0.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting sentencepiece==0.1.99 (from llava==1.2.2.post1)\n",
            "  Downloading sentencepiece-0.1.99-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting shortuuid (from llava==1.2.2.post1)\n",
            "  Downloading shortuuid-1.0.13-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting accelerate==0.21.0 (from llava==1.2.2.post1)\n",
            "  Downloading accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (from llava==1.2.2.post1) (0.14.0)\n",
            "Collecting bitsandbytes (from llava==1.2.2.post1)\n",
            "  Downloading bitsandbytes-0.45.2-py3-none-manylinux_2_24_x86_64.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from llava==1.2.2.post1) (2.10.6)\n",
            "Collecting markdown2[all] (from llava==1.2.2.post1)\n",
            "  Downloading markdown2-2.5.3-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llava==1.2.2.post1) (1.26.4)\n",
            "Collecting scikit-learn==1.2.2 (from llava==1.2.2.post1)\n",
            "  Downloading scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting gradio==4.16.0 (from llava==1.2.2.post1)\n",
            "  Downloading gradio-4.16.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting gradio_client==0.8.1 (from llava==1.2.2.post1)\n",
            "  Downloading gradio_client-0.8.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from llava==1.2.2.post1) (2.32.3)\n",
            "Collecting httpx==0.24.0 (from llava==1.2.2.post1)\n",
            "  Downloading httpx-0.24.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting uvicorn (from llava==1.2.2.post1)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting fastapi (from llava==1.2.2.post1)\n",
            "  Downloading fastapi-0.115.8-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting einops==0.6.1 (from llava==1.2.2.post1)\n",
            "  Downloading einops-0.6.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting einops-exts==0.0.4 (from llava==1.2.2.post1)\n",
            "  Downloading einops_exts-0.0.4-py3-none-any.whl.metadata (621 bytes)\n",
            "Collecting timm==0.6.13 (from llava==1.2.2.post1)\n",
            "  Downloading timm-0.6.13-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.21.0->llava==1.2.2.post1) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==0.21.0->llava==1.2.2.post1) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate==0.21.0->llava==1.2.2.post1) (6.0.2)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio==4.16.0->llava==1.2.2.post1)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (5.5.0)\n",
            "Collecting ffmpy (from gradio==4.16.0->llava==1.2.2.post1)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (0.28.1)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.11/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (6.5.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (3.1.5)\n",
            "Collecting markupsafe~=2.0 (from gradio==4.16.0->llava==1.2.2.post1)\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (3.10.0)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (3.10.15)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (2.2.2)\n",
            "Collecting pillow<11.0,>=8.0 (from gradio==4.16.0->llava==1.2.2.post1)\n",
            "  Downloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting pydub (from gradio==4.16.0->llava==1.2.2.post1)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart (from gradio==4.16.0->llava==1.2.2.post1)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting ruff>=0.1.7 (from gradio==4.16.0->llava==1.2.2.post1)\n",
            "  Downloading ruff-0.9.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio==4.16.0->llava==1.2.2.post1)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio==4.16.0->llava==1.2.2.post1)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.9 in /usr/local/lib/python3.11/dist-packages (from typer[all]<1.0,>=0.9->gradio==4.16.0->llava==1.2.2.post1) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (4.12.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio_client==0.8.1->llava==1.2.2.post1) (2024.10.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio_client==0.8.1->llava==1.2.2.post1)\n",
            "  Downloading websockets-11.0.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx==0.24.0->llava==1.2.2.post1) (2025.1.31)\n",
            "Collecting httpcore<0.18.0,>=0.15.0 (from httpx==0.24.0->llava==1.2.2.post1)\n",
            "  Downloading httpcore-0.17.3-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx==0.24.0->llava==1.2.2.post1) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx==0.24.0->llava==1.2.2.post1) (1.3.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2->llava==1.2.2.post1) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2->llava==1.2.2.post1) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2->llava==1.2.2.post1) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2->llava==1.2.2.post1) (3.17.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2->llava==1.2.2.post1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2->llava==1.2.2.post1) (3.4.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.1.2->llava==1.2.2.post1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.1.2->llava==1.2.2.post1)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.1.2->llava==1.2.2.post1)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.1.2->llava==1.2.2.post1)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.1.2->llava==1.2.2.post1)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.1.2->llava==1.2.2.post1)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.1.2->llava==1.2.2.post1)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.1.2->llava==1.2.2.post1)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.1.2->llava==1.2.2.post1)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.18.1 (from torch==2.1.2->llava==1.2.2.post1)\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.1.2->llava==1.2.2.post1)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.1.0 (from torch==2.1.2->llava==1.2.2.post1)\n",
            "  Downloading triton-2.1.0-0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2->llava==1.2.2.post1) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2->llava==1.2.2.post1) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2->llava==1.2.2.post1) (4.67.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.2->llava==1.2.2.post1) (12.5.82)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->llava==1.2.2.post1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->llava==1.2.2.post1) (2.27.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn->llava==1.2.2.post1) (8.1.8)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn->llava==1.2.2.post1) (0.14.0)\n",
            "Collecting starlette<0.46.0,>=0.40.0 (from fastapi->llava==1.2.2.post1)\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: pygments>=2.7.3 in /usr/local/lib/python3.11/dist-packages (from markdown2[all]->llava==1.2.2.post1) (2.18.0)\n",
            "Collecting wavedrom (from markdown2[all]->llava==1.2.2.post1)\n",
            "  Downloading wavedrom-2.0.3.post3.tar.gz (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.7/137.7 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting latex2mathml (from markdown2[all]->llava==1.2.2.post1)\n",
            "  Downloading latex2mathml-3.77.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->llava==1.2.2.post1) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->llava==1.2.2.post1) (2.3.0)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6.0,>=4.2.0->gradio==4.16.0->llava==1.2.2.post1) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6.0,>=4.2.0->gradio==4.16.0->llava==1.2.2.post1) (1.27.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx==0.24.0->llava==1.2.2.post1) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==4.16.0->llava==1.2.2.post1) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==4.16.0->llava==1.2.2.post1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==4.16.0->llava==1.2.2.post1) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==4.16.0->llava==1.2.2.post1) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==4.16.0->llava==1.2.2.post1) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==4.16.0->llava==1.2.2.post1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==4.16.0->llava==1.2.2.post1) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==4.16.0->llava==1.2.2.post1) (2025.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9->gradio==4.16.0->llava==1.2.2.post1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9->gradio==4.16.0->llava==1.2.2.post1) (13.9.4)\n",
            "\u001b[33mWARNING: typer 0.15.1 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.1.2->llava==1.2.2.post1) (1.3.0)\n",
            "Collecting svgwrite (from wavedrom->markdown2[all]->llava==1.2.2.post1)\n",
            "  Downloading svgwrite-1.4.3-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from wavedrom->markdown2[all]->llava==1.2.2.post1) (1.17.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.16.0->llava==1.2.2.post1) (25.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.16.0->llava==1.2.2.post1) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.16.0->llava==1.2.2.post1) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.16.0->llava==1.2.2.post1) (0.22.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.9->typer[all]<1.0,>=0.9->gradio==4.16.0->llava==1.2.2.post1) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.9->typer[all]<1.0,>=0.9->gradio==4.16.0->llava==1.2.2.post1) (0.1.2)\n",
            "Downloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading einops_exts-0.0.4-py3-none-any.whl (3.9 kB)\n",
            "Downloading gradio-4.16.0-py3-none-any.whl (16.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m105.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-0.8.1-py3-none-any.whl (305 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.2/305.2 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.24.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.3/75.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m122.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentencepiece-0.1.99-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading timm-0.6.13-py3-none-any.whl (549 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 kB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m97.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.1.2-cp311-cp311-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.16.2-cp311-cp311-manylinux1_x86_64.whl (6.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m117.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m119.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m102.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading triton-2.1.0-0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.45.2-py3-none-manylinux_2_24_x86_64.whl (69.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.8-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shortuuid-1.0.13-py3-none-any.whl (10 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading httpcore-0.17.3-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m105.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruff-0.9.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m114.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-11.0.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.6/130.6 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading latex2mathml-3.77.0-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.7/73.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading markdown2-2.5.3-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading svgwrite-1.4.3-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/67.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: llava, wavedrom\n",
            "  Building editable for llava (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llava: filename=llava-1.2.2.post1-0.editable-py3-none-any.whl size=17852 sha256=587b688a021d803157ecfe51191c9be80830850998a88492a56b1ddfe08a80f3\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7plg3zhq/wheels/55/a1/dd/fc37ed4f847b25c140c977a5e08209dfbe50be519f62fb82a9\n",
            "  Building wheel for wavedrom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wavedrom: filename=wavedrom-2.0.3.post3-py2.py3-none-any.whl size=30082 sha256=f6ca4a3026cab1cc9aaeed47c92bd84d76f5ba17c0e89ccb47263eca6424c339\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/cf/3b/4dcf6b22fa41c5ece715fa5f4e05afd683e7b0ce0f2fcc7bb6\n",
            "Successfully built llava wavedrom\n",
            "Installing collected packages: sentencepiece, pydub, websockets, uvicorn, triton, tomlkit, svgwrite, shortuuid, semantic-version, ruff, python-multipart, pillow, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, markupsafe, markdown2, latex2mathml, ffmpy, einops, aiofiles, wavedrom, starlette, scikit-learn, nvidia-cusolver-cu12, nvidia-cudnn-cu12, httpcore, einops-exts, torch, tokenizers, httpx, fastapi, transformers, torchvision, gradio_client, bitsandbytes, accelerate, timm, gradio, llava\n",
            "  Attempting uninstall: sentencepiece\n",
            "    Found existing installation: sentencepiece 0.2.0\n",
            "    Uninstalling sentencepiece-0.2.0:\n",
            "      Successfully uninstalled sentencepiece-0.2.0\n",
            "  Attempting uninstall: websockets\n",
            "    Found existing installation: websockets 14.2\n",
            "    Uninstalling websockets-14.2:\n",
            "      Successfully uninstalled websockets-14.2\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.1.0\n",
            "    Uninstalling triton-3.1.0:\n",
            "      Successfully uninstalled triton-3.1.0\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.1.0\n",
            "    Uninstalling pillow-11.1.0:\n",
            "      Successfully uninstalled pillow-11.1.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: einops\n",
            "    Found existing installation: einops 0.8.1\n",
            "    Uninstalling einops-0.8.1:\n",
            "      Successfully uninstalled einops-0.8.1\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: httpcore\n",
            "    Found existing installation: httpcore 1.0.7\n",
            "    Uninstalling httpcore-1.0.7:\n",
            "      Successfully uninstalled httpcore-1.0.7\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu124\n",
            "    Uninstalling torch-2.5.1+cu124:\n",
            "      Successfully uninstalled torch-2.5.1+cu124\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.15.2\n",
            "    Uninstalling tokenizers-0.15.2:\n",
            "      Successfully uninstalled tokenizers-0.15.2\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.36.2\n",
            "    Uninstalling transformers-4.36.2:\n",
            "      Successfully uninstalled transformers-4.36.2\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.20.1+cu124\n",
            "    Uninstalling torchvision-0.20.1+cu124:\n",
            "      Successfully uninstalled torchvision-0.20.1+cu124\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.3.0\n",
            "    Uninstalling accelerate-1.3.0:\n",
            "      Successfully uninstalled accelerate-1.3.0\n",
            "  Attempting uninstall: timm\n",
            "    Found existing installation: timm 1.0.14\n",
            "    Uninstalling timm-1.0.14:\n",
            "      Successfully uninstalled timm-1.0.14\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-genai 0.8.0 requires websockets<15.0dev,>=13.0, but you have websockets 11.0.3 which is incompatible.\n",
            "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "sentence-transformers 3.4.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.37.2 which is incompatible.\n",
            "torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.1.2 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.21.0 aiofiles-23.2.1 bitsandbytes-0.45.2 einops-0.6.1 einops-exts-0.0.4 fastapi-0.115.8 ffmpy-0.5.0 gradio-4.16.0 gradio_client-0.8.1 httpcore-0.17.3 httpx-0.24.0 latex2mathml-3.77.0 llava-1.2.2.post1 markdown2-2.5.3 markupsafe-2.1.5 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvtx-cu12-12.1.105 pillow-10.4.0 pydub-0.25.1 python-multipart-0.0.20 ruff-0.9.7 scikit-learn-1.2.2 semantic-version-2.10.0 sentencepiece-0.1.99 shortuuid-1.0.13 starlette-0.45.3 svgwrite-1.4.3 timm-0.6.13 tokenizers-0.15.1 tomlkit-0.12.0 torch-2.1.2 torchvision-0.16.2 transformers-4.37.2 triton-2.1.0 uvicorn-0.34.0 wavedrom-2.0.3.post3 websockets-11.0.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              },
              "id": "d5a859b2de6c4871aa9fdd1f89bc21e9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -e \".[train]\"\n",
        "!pip install flash-attn --no-build-isolation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7m35pOywMlUv",
        "outputId": "4a33e32a-ee8f-4f56-8dee-010ee464114f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/LLaVA\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch==2.1.2 in /usr/local/lib/python3.11/dist-packages (from llava==1.2.2.post1) (2.1.2)\n",
            "Requirement already satisfied: torchvision==0.16.2 in /usr/local/lib/python3.11/dist-packages (from llava==1.2.2.post1) (0.16.2)\n",
            "Requirement already satisfied: transformers==4.37.2 in /usr/local/lib/python3.11/dist-packages (from llava==1.2.2.post1) (4.37.2)\n",
            "Requirement already satisfied: tokenizers==0.15.1 in /usr/local/lib/python3.11/dist-packages (from llava==1.2.2.post1) (0.15.1)\n",
            "Requirement already satisfied: sentencepiece==0.1.99 in /usr/local/lib/python3.11/dist-packages (from llava==1.2.2.post1) (0.1.99)\n",
            "Requirement already satisfied: shortuuid in /usr/local/lib/python3.11/dist-packages (from llava==1.2.2.post1) (1.0.13)\n",
            "Requirement already satisfied: accelerate==0.21.0 in /usr/local/lib/python3.11/dist-packages (from llava==1.2.2.post1) (0.21.0)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (from llava==1.2.2.post1) (0.14.0)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (from llava==1.2.2.post1) (0.45.2)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from llava==1.2.2.post1) (2.10.6)\n",
            "Requirement already satisfied: markdown2[all] in /usr/local/lib/python3.11/dist-packages (from llava==1.2.2.post1) (2.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llava==1.2.2.post1) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn==1.2.2 in /usr/local/lib/python3.11/dist-packages (from llava==1.2.2.post1) (1.2.2)\n",
            "Requirement already satisfied: gradio==4.16.0 in /usr/local/lib/python3.11/dist-packages (from llava==1.2.2.post1) (4.16.0)\n",
            "Requirement already satisfied: gradio_client==0.8.1 in /usr/local/lib/python3.11/dist-packages (from llava==1.2.2.post1) (0.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from llava==1.2.2.post1) (2.32.3)\n",
            "Requirement already satisfied: httpx==0.24.0 in /usr/local/lib/python3.11/dist-packages (from llava==1.2.2.post1) (0.24.0)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (from llava==1.2.2.post1) (0.34.0)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (from llava==1.2.2.post1) (0.115.8)\n",
            "Requirement already satisfied: einops==0.6.1 in /usr/local/lib/python3.11/dist-packages (from llava==1.2.2.post1) (0.6.1)\n",
            "Requirement already satisfied: einops-exts==0.0.4 in /usr/local/lib/python3.11/dist-packages (from llava==1.2.2.post1) (0.0.4)\n",
            "Requirement already satisfied: timm==0.6.13 in /usr/local/lib/python3.11/dist-packages (from llava==1.2.2.post1) (0.6.13)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.21.0->llava==1.2.2.post1) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==0.21.0->llava==1.2.2.post1) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate==0.21.0->llava==1.2.2.post1) (6.0.2)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (5.5.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (0.5.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (0.28.1)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.11/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (6.5.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (3.1.5)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (3.10.0)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (3.10.15)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (2.2.2)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (10.4.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (0.25.1)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.11/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (0.9.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.9 in /usr/local/lib/python3.11/dist-packages (from typer[all]<1.0,>=0.9->gradio==4.16.0->llava==1.2.2.post1) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.16.0->llava==1.2.2.post1) (4.12.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio_client==0.8.1->llava==1.2.2.post1) (2024.10.0)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio_client==0.8.1->llava==1.2.2.post1) (11.0.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx==0.24.0->llava==1.2.2.post1) (2025.1.31)\n",
            "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from httpx==0.24.0->llava==1.2.2.post1) (0.17.3)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx==0.24.0->llava==1.2.2.post1) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx==0.24.0->llava==1.2.2.post1) (1.3.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2->llava==1.2.2.post1) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2->llava==1.2.2.post1) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2->llava==1.2.2.post1) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2->llava==1.2.2.post1) (3.17.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2->llava==1.2.2.post1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2->llava==1.2.2.post1) (3.4.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2->llava==1.2.2.post1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2->llava==1.2.2.post1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2->llava==1.2.2.post1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2->llava==1.2.2.post1) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2->llava==1.2.2.post1) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2->llava==1.2.2.post1) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2->llava==1.2.2.post1) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2->llava==1.2.2.post1) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2->llava==1.2.2.post1) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2->llava==1.2.2.post1) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2->llava==1.2.2.post1) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2->llava==1.2.2.post1) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2->llava==1.2.2.post1) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2->llava==1.2.2.post1) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2->llava==1.2.2.post1) (4.67.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.2->llava==1.2.2.post1) (12.5.82)\n",
            "Collecting deepspeed==0.12.6 (from llava==1.2.2.post1)\n",
            "  Downloading deepspeed-0.12.6.tar.gz (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ninja (from llava==1.2.2.post1)\n",
            "  Downloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from llava==1.2.2.post1) (0.19.6)\n",
            "Collecting hjson (from deepspeed==0.12.6->llava==1.2.2.post1)\n",
            "  Downloading hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from deepspeed==0.12.6->llava==1.2.2.post1) (9.0.0)\n",
            "Collecting pynvml (from deepspeed==0.12.6->llava==1.2.2.post1)\n",
            "  Downloading pynvml-12.0.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->llava==1.2.2.post1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->llava==1.2.2.post1) (2.27.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn->llava==1.2.2.post1) (8.1.8)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn->llava==1.2.2.post1) (0.14.0)\n",
            "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi->llava==1.2.2.post1) (0.45.3)\n",
            "Requirement already satisfied: pygments>=2.7.3 in /usr/local/lib/python3.11/dist-packages (from markdown2[all]->llava==1.2.2.post1) (2.18.0)\n",
            "Requirement already satisfied: wavedrom in /usr/local/lib/python3.11/dist-packages (from markdown2[all]->llava==1.2.2.post1) (2.0.3.post3)\n",
            "Requirement already satisfied: latex2mathml in /usr/local/lib/python3.11/dist-packages (from markdown2[all]->llava==1.2.2.post1) (3.77.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->llava==1.2.2.post1) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->llava==1.2.2.post1) (2.3.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb->llava==1.2.2.post1) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->llava==1.2.2.post1) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb->llava==1.2.2.post1) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb->llava==1.2.2.post1) (4.25.6)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->llava==1.2.2.post1) (2.22.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb->llava==1.2.2.post1) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb->llava==1.2.2.post1) (75.1.0)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6.0,>=4.2.0->gradio==4.16.0->llava==1.2.2.post1) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6.0,>=4.2.0->gradio==4.16.0->llava==1.2.2.post1) (1.27.1)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb->llava==1.2.2.post1) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->llava==1.2.2.post1) (4.0.12)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx==0.24.0->llava==1.2.2.post1) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==4.16.0->llava==1.2.2.post1) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==4.16.0->llava==1.2.2.post1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==4.16.0->llava==1.2.2.post1) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==4.16.0->llava==1.2.2.post1) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==4.16.0->llava==1.2.2.post1) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==4.16.0->llava==1.2.2.post1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==4.16.0->llava==1.2.2.post1) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==4.16.0->llava==1.2.2.post1) (2025.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9->gradio==4.16.0->llava==1.2.2.post1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9->gradio==4.16.0->llava==1.2.2.post1) (13.9.4)\n",
            "\u001b[33mWARNING: typer 0.15.1 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting nvidia-ml-py<13.0.0a0,>=12.0.0 (from pynvml->deepspeed==0.12.6->llava==1.2.2.post1)\n",
            "  Downloading nvidia_ml_py-12.570.86-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.1.2->llava==1.2.2.post1) (1.3.0)\n",
            "Requirement already satisfied: svgwrite in /usr/local/lib/python3.11/dist-packages (from wavedrom->markdown2[all]->llava==1.2.2.post1) (1.4.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->llava==1.2.2.post1) (5.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.16.0->llava==1.2.2.post1) (25.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.16.0->llava==1.2.2.post1) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.16.0->llava==1.2.2.post1) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.16.0->llava==1.2.2.post1) (0.22.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.9->typer[all]<1.0,>=0.9->gradio==4.16.0->llava==1.2.2.post1) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.9->typer[all]<1.0,>=0.9->gradio==4.16.0->llava==1.2.2.post1) (0.1.2)\n",
            "Downloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.9/422.9 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pynvml-12.0.0-py3-none-any.whl (26 kB)\n",
            "Downloading nvidia_ml_py-12.570.86-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: llava, deepspeed\n",
            "  Building editable for llava (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llava: filename=llava-1.2.2.post1-0.editable-py3-none-any.whl size=17852 sha256=bfdf8bbfdbe490be6e6ebb9918eb8df64bbb70ea106a6f30ba2c31c5a88c1a0c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-lk7211iz/wheels/55/a1/dd/fc37ed4f847b25c140c977a5e08209dfbe50be519f62fb82a9\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.12.6-py3-none-any.whl size=1306719 sha256=d4f4b482e9e54920e8836853289388eff105e58fc65fe4dd62a3ada391f1dcf3\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/e6/c6/bf503773d88c9375949b2037f80d39d65f1fb960dac01049c5\n",
            "Successfully built llava deepspeed\n",
            "Installing collected packages: nvidia-ml-py, hjson, pynvml, ninja, deepspeed, llava\n",
            "  Attempting uninstall: llava\n",
            "    Found existing installation: llava 1.2.2.post1\n",
            "    Uninstalling llava-1.2.2.post1:\n",
            "      Successfully uninstalled llava-1.2.2.post1\n",
            "Successfully installed deepspeed-0.12.6 hjson-3.1.0 llava-1.2.2.post1 ninja-1.11.1.3 nvidia-ml-py-12.570.86 pynvml-12.0.0\n",
            "Collecting flash-attn\n",
            "  Downloading flash_attn-2.7.4.post1.tar.gz (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from flash-attn) (2.1.2)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from flash-attn) (0.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->flash-attn) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->flash-attn) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->flash-attn) (1.3.0)\n",
            "Building wheels for collected packages: flash-attn\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for flash-attn\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for flash-attn\n",
            "Failed to build flash-attn\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (flash-attn)\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.34.1"
      ],
      "metadata": {
        "id": "MoTEHw_FQRDj",
        "outputId": "e5e74822-3121-47c7-9646-a80e11de7491",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.34.1\n",
            "  Downloading transformers-4.34.1-py3-none-any.whl.metadata (121 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/121.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.5/121.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.34.1) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from transformers==4.34.1) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.34.1) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.34.1) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.34.1) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.34.1) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.34.1) (2.32.3)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers==4.34.1)\n",
            "  Downloading tokenizers-0.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.34.1) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.34.1) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.34.1) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.34.1) (4.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers==4.34.1)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.34.1) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.34.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.34.1) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.34.1) (2025.1.31)\n",
            "Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m104.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: huggingface-hub, tokenizers, transformers\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.28.1\n",
            "    Uninstalling huggingface-hub-0.28.1:\n",
            "      Successfully uninstalled huggingface-hub-0.28.1\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.15.1\n",
            "    Uninstalling tokenizers-0.15.1:\n",
            "      Successfully uninstalled tokenizers-0.15.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.37.2\n",
            "    Uninstalling transformers-4.37.2:\n",
            "      Successfully uninstalled transformers-4.37.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gradio-client 0.8.1 requires huggingface-hub>=0.19.3, but you have huggingface-hub 0.17.3 which is incompatible.\n",
            "llava 1.2.2.post1 requires tokenizers==0.15.1, but you have tokenizers 0.14.1 which is incompatible.\n",
            "llava 1.2.2.post1 requires transformers==4.37.2, but you have transformers 4.34.1 which is incompatible.\n",
            "gradio 4.16.0 requires huggingface-hub>=0.19.3, but you have huggingface-hub 0.17.3 which is incompatible.\n",
            "peft 0.14.0 requires huggingface-hub>=0.25.0, but you have huggingface-hub 0.17.3 which is incompatible.\n",
            "sentence-transformers 3.4.1 requires huggingface-hub>=0.20.0, but you have huggingface-hub 0.17.3 which is incompatible.\n",
            "sentence-transformers 3.4.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.34.1 which is incompatible.\n",
            "diffusers 0.32.2 requires huggingface-hub>=0.23.2, but you have huggingface-hub 0.17.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed huggingface-hub-0.17.3 tokenizers-0.14.1 transformers-4.34.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install peft==0.10.0 transformers==4.37.2"
      ],
      "metadata": {
        "id": "DXP0PV8-RFz5",
        "outputId": "3f3b937e-0b19-439e-88b7-fd672642c6cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting peft==0.10.0\n",
            "  Downloading peft-0.10.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting transformers==4.37.2\n",
            "  Using cached transformers-4.37.2-py3-none-any.whl.metadata (129 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (2.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (4.67.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (0.21.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (0.5.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (0.29.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2) (3.17.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2) (0.14.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (4.12.2)\n",
            "INFO: pip is looking at multiple versions of tokenizers to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers==4.37.2)\n",
            "  Using cached tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft==0.10.0) (12.5.82)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.37.2) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.37.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.37.2) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.37.2) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft==0.10.0) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.13.0->peft==0.10.0) (1.3.0)\n",
            "Downloading peft-0.10.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached transformers-4.37.2-py3-none-any.whl (8.4 MB)\n",
            "Using cached tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "Installing collected packages: tokenizers, transformers, peft\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.14.1\n",
            "    Uninstalling tokenizers-0.14.1:\n",
            "      Successfully uninstalled tokenizers-0.14.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.34.1\n",
            "    Uninstalling transformers-4.34.1:\n",
            "      Successfully uninstalled transformers-4.34.1\n",
            "  Attempting uninstall: peft\n",
            "    Found existing installation: peft 0.14.0\n",
            "    Uninstalling peft-0.14.0:\n",
            "      Successfully uninstalled peft-0.14.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llava 1.2.2.post1 requires tokenizers==0.15.1, but you have tokenizers 0.15.2 which is incompatible.\n",
            "sentence-transformers 3.4.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.37.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed peft-0.10.0 tokenizers-0.15.2 transformers-4.37.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt update\n",
        "!sudo apt install g++-9\n",
        "!sudo apt install gcc-9\n"
      ],
      "metadata": {
        "id": "HRctUqzcUT5H",
        "outputId": "dc7ffa17-40a5-4b46-8d17-0f855ef5de2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "\r            \rGet:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (185.1\u001b[0m\u001b[33m\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (185.1\u001b[0m\r                                                                               \rGet:3 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,317 kB]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,700 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:11 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,661 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,610 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,526 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,230 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,939 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\n",
            "Fetched 21.4 MB in 2s (10.9 MB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "35 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  cpp-9 gcc-9 gcc-9-base libasan5 libgcc-9-dev libstdc++-9-dev\n",
            "Suggested packages:\n",
            "  gcc-9-locales g++-9-multilib gcc-9-doc gcc-9-multilib libstdc++-9-doc\n",
            "The following NEW packages will be installed:\n",
            "  cpp-9 g++-9 gcc-9 gcc-9-base libasan5 libgcc-9-dev libstdc++-9-dev\n",
            "0 upgraded, 7 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 41.2 MB of archives.\n",
            "After this operation, 138 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 gcc-9-base amd64 9.5.0-1ubuntu1~22.04 [19.8 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 cpp-9 amd64 9.5.0-1ubuntu1~22.04 [10.6 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libasan5 amd64 9.5.0-1ubuntu1~22.04 [3,140 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libgcc-9-dev amd64 9.5.0-1ubuntu1~22.04 [2,520 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 gcc-9 amd64 9.5.0-1ubuntu1~22.04 [11.3 MB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libstdc++-9-dev amd64 9.5.0-1ubuntu1~22.04 [1,824 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 g++-9 amd64 9.5.0-1ubuntu1~22.04 [11.9 MB]\n",
            "Fetched 41.2 MB in 2s (17.9 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 7.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package gcc-9-base:amd64.\n",
            "(Reading database ... 124926 files and directories currently installed.)\n",
            "Preparing to unpack .../0-gcc-9-base_9.5.0-1ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking gcc-9-base:amd64 (9.5.0-1ubuntu1~22.04) ...\n",
            "Selecting previously unselected package cpp-9.\n",
            "Preparing to unpack .../1-cpp-9_9.5.0-1ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking cpp-9 (9.5.0-1ubuntu1~22.04) ...\n",
            "Selecting previously unselected package libasan5:amd64.\n",
            "Preparing to unpack .../2-libasan5_9.5.0-1ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking libasan5:amd64 (9.5.0-1ubuntu1~22.04) ...\n",
            "Selecting previously unselected package libgcc-9-dev:amd64.\n",
            "Preparing to unpack .../3-libgcc-9-dev_9.5.0-1ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking libgcc-9-dev:amd64 (9.5.0-1ubuntu1~22.04) ...\n",
            "Selecting previously unselected package gcc-9.\n",
            "Preparing to unpack .../4-gcc-9_9.5.0-1ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking gcc-9 (9.5.0-1ubuntu1~22.04) ...\n",
            "Selecting previously unselected package libstdc++-9-dev:amd64.\n",
            "Preparing to unpack .../5-libstdc++-9-dev_9.5.0-1ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking libstdc++-9-dev:amd64 (9.5.0-1ubuntu1~22.04) ...\n",
            "Selecting previously unselected package g++-9.\n",
            "Preparing to unpack .../6-g++-9_9.5.0-1ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking g++-9 (9.5.0-1ubuntu1~22.04) ...\n",
            "Setting up gcc-9-base:amd64 (9.5.0-1ubuntu1~22.04) ...\n",
            "Setting up libasan5:amd64 (9.5.0-1ubuntu1~22.04) ...\n",
            "Setting up cpp-9 (9.5.0-1ubuntu1~22.04) ...\n",
            "Setting up libgcc-9-dev:amd64 (9.5.0-1ubuntu1~22.04) ...\n",
            "Setting up gcc-9 (9.5.0-1ubuntu1~22.04) ...\n",
            "Setting up libstdc++-9-dev:amd64 (9.5.0-1ubuntu1~22.04) ...\n",
            "Setting up g++-9 (9.5.0-1ubuntu1~22.04) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "gcc-9 is already the newest version (9.5.0-1ubuntu1~22.04).\n",
            "gcc-9 set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version\n",
        "!pip install flash-attn --no-build-isolation --no-cache-dir"
      ],
      "metadata": {
        "id": "pnuLaASBSEx2",
        "outputId": "76216f42-587a-416e-da7f-42c709c6fb1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n",
            "Collecting flash-attn\n",
            "  Downloading flash_attn-2.7.4.post1.tar.gz (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from flash-attn) (2.1.2)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from flash-attn) (0.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->flash-attn) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->flash-attn) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->flash-attn) (1.3.0)\n",
            "Building wheels for collected packages: flash-attn\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for flash-attn\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for flash-attn\n",
            "Failed to build flash-attn\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (flash-attn)\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/bin/bash\n",
        "\n",
        "!deepspeed llava/train/train_mem.py \\\n",
        "    --deepspeed ./scripts/zero3.json \\\n",
        "    --model_name_or_path liuhaotian/llava-v1.5-13b \\\n",
        "    --version v1 \\\n",
        "    --data_path ./playground/data/llava_v1_5_mix665k.json \\\n",
        "    --image_folder ./playground/data \\\n",
        "    --vision_tower openai/clip-vit-large-patch14-336 \\\n",
        "    --mm_projector_type mlp2x_gelu \\\n",
        "    --mm_vision_select_layer -2 \\\n",
        "    --mm_use_im_start_end False \\\n",
        "    --mm_use_im_patch_token False \\\n",
        "    --image_aspect_ratio pad \\\n",
        "    --group_by_modality_length True \\\n",
        "    --bf16 True \\\n",
        "    --output_dir ./checkpoints/llava-v1.5-13b-task \\\n",
        "    --num_train_epochs 1 \\\n",
        "    --per_device_train_batch_size 16 \\\n",
        "    --per_device_eval_batch_size 4 \\\n",
        "    --gradient_accumulation_steps 1 \\\n",
        "    --evaluation_strategy \"no\" \\\n",
        "    --save_strategy \"steps\" \\\n",
        "    --save_steps 50000 \\\n",
        "    --save_total_limit 1 \\\n",
        "    --learning_rate 2e-5 \\\n",
        "    --weight_decay 0. \\\n",
        "    --warmup_ratio 0.03 \\\n",
        "    --lr_scheduler_type \"cosine\" \\\n",
        "    --logging_steps 1 \\\n",
        "    --tf32 True \\\n",
        "    --model_max_length 2048 \\\n",
        "    --gradient_checkpointing True \\\n",
        "    --dataloader_num_workers 4 \\\n",
        "    --lazy_preprocess True \\\n",
        "    --report_to wandb"
      ],
      "metadata": {
        "id": "UMUaAoHwO9fg",
        "outputId": "f6ddf9be-41bd-478e-e011-e53f0e1aa36f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025-02-24 17:02:56,447] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "2025-02-24 17:02:59.079888: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1740416579.102342   11253 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1740416579.109284   11253 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "[2025-02-24 17:03:02,412] [WARNING] [runner.py:202:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
            "[2025-02-24 17:03:02,412] [INFO] [runner.py:571:main] cmd = /usr/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None llava/train/train_mem.py --deepspeed ./scripts/zero3.json --model_name_or_path liuhaotian/llava-v1.5-13b --version v1 --data_path ./playground/data/llava_v1_5_mix665k.json --image_folder ./playground/data --vision_tower openai/clip-vit-large-patch14-336 --mm_projector_type mlp2x_gelu --mm_vision_select_layer -2 --mm_use_im_start_end False --mm_use_im_patch_token False --image_aspect_ratio pad --group_by_modality_length True --bf16 True --output_dir ./checkpoints/llava-v1.5-13b-task --num_train_epochs 1 --per_device_train_batch_size 16 --per_device_eval_batch_size 4 --gradient_accumulation_steps 1 --evaluation_strategy no --save_strategy steps --save_steps 50000 --save_total_limit 1 --learning_rate 2e-5 --weight_decay 0. --warmup_ratio 0.03 --lr_scheduler_type cosine --logging_steps 1 --tf32 True --model_max_length 2048 --gradient_checkpointing True --dataloader_num_workers 4 --lazy_preprocess True --report_to wandb\n",
            "[2025-02-24 17:03:04,779] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "2025-02-24 17:03:07.308267: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1740416587.330156   11360 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1740416587.336827   11360 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "[2025-02-24 17:03:10,586] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.22.3-1+cuda12.5\n",
            "[2025-02-24 17:03:10,586] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE_VERSION=2.22.3-1\n",
            "[2025-02-24 17:03:10,586] [INFO] [launch.py:138:main] 0 NCCL_VERSION=2.22.3-1\n",
            "[2025-02-24 17:03:10,586] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev\n",
            "[2025-02-24 17:03:10,586] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE=libnccl2=2.22.3-1+cuda12.5\n",
            "[2025-02-24 17:03:10,586] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE_NAME=libnccl2\n",
            "[2025-02-24 17:03:10,586] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE_VERSION=2.22.3-1\n",
            "[2025-02-24 17:03:10,586] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0]}\n",
            "[2025-02-24 17:03:10,586] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=1, node_rank=0\n",
            "[2025-02-24 17:03:10,586] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})\n",
            "[2025-02-24 17:03:10,586] [INFO] [launch.py:163:main] dist_world_size=1\n",
            "[2025-02-24 17:03:10,586] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0\n",
            "[2025-02-24 17:03:14,158] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "2025-02-24 17:03:15.499755: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1740416595.521998   11438 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1740416595.528849   11438 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "[2025-02-24 17:03:18,937] [INFO] [comm.py:637:init_distributed] cdb=None\n",
            "[2025-02-24 17:03:18,937] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "config.json: 100% 1.16k/1.16k [00:00<00:00, 10.2MB/s]\n",
            "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n",
            "pytorch_model.bin.index.json: 100% 33.7k/33.7k [00:00<00:00, 1.59MB/s]\n",
            "Downloading shards:   0% 0/3 [00:00<?, ?it/s]\n",
            "pytorch_model-00001-of-00003.bin:   0% 0.00/9.95G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   0% 10.5M/9.95G [00:00<01:38, 101MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   0% 31.5M/9.95G [00:00<01:00, 163MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   1% 62.9M/9.95G [00:00<00:44, 222MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   1% 94.4M/9.95G [00:00<00:41, 239MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   1% 126M/9.95G [00:00<00:40, 242MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   2% 157M/9.95G [00:00<00:40, 241MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   2% 189M/9.95G [00:00<00:40, 242MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   2% 220M/9.95G [00:00<00:39, 246MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   3% 252M/9.95G [00:01<00:39, 243MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   3% 283M/9.95G [00:01<00:39, 242MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   3% 315M/9.95G [00:01<00:38, 247MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   3% 346M/9.95G [00:01<00:39, 246MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   4% 377M/9.95G [00:01<00:39, 242MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   4% 409M/9.95G [00:01<00:40, 238MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   4% 440M/9.95G [00:01<00:39, 238MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   5% 472M/9.95G [00:01<00:39, 237MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   5% 503M/9.95G [00:02<00:39, 239MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   5% 535M/9.95G [00:02<00:39, 237MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   6% 566M/9.95G [00:02<00:39, 238MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   6% 598M/9.95G [00:02<00:39, 237MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   6% 629M/9.95G [00:02<00:39, 236MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   7% 661M/9.95G [00:02<00:38, 238MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   7% 692M/9.95G [00:02<00:39, 236MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   7% 724M/9.95G [00:03<00:39, 235MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   8% 755M/9.95G [00:03<00:38, 241MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   8% 786M/9.95G [00:03<00:38, 240MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   8% 818M/9.95G [00:03<00:37, 243MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   9% 849M/9.95G [00:03<00:37, 242MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   9% 881M/9.95G [00:03<00:37, 245MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   9% 912M/9.95G [00:03<00:37, 241MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:   9% 944M/9.95G [00:03<00:37, 241MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  10% 975M/9.95G [00:04<00:36, 243MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  10% 1.01G/9.95G [00:04<00:36, 247MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  10% 1.04G/9.95G [00:04<00:36, 247MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  11% 1.07G/9.95G [00:04<00:39, 223MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  11% 1.10G/9.95G [00:04<00:38, 228MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  11% 1.13G/9.95G [00:04<00:38, 230MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  12% 1.16G/9.95G [00:04<00:39, 223MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  12% 1.20G/9.95G [00:05<00:38, 225MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  12% 1.23G/9.95G [00:05<00:38, 230MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  13% 1.26G/9.95G [00:05<00:45, 190MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  13% 1.29G/9.95G [00:05<00:42, 203MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  13% 1.32G/9.95G [00:05<00:41, 208MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  14% 1.35G/9.95G [00:05<00:39, 217MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  14% 1.38G/9.95G [00:05<00:38, 225MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  14% 1.42G/9.95G [00:06<00:37, 229MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  15% 1.45G/9.95G [00:06<00:36, 232MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  15% 1.48G/9.95G [00:06<00:45, 186MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  15% 1.51G/9.95G [00:06<00:42, 198MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  15% 1.54G/9.95G [00:06<00:40, 206MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  16% 1.57G/9.95G [00:06<00:40, 206MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  16% 1.60G/9.95G [00:07<00:39, 210MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  16% 1.64G/9.95G [00:07<00:38, 214MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  17% 1.67G/9.95G [00:07<00:38, 217MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  17% 1.70G/9.95G [00:07<00:42, 196MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  17% 1.73G/9.95G [00:07<00:39, 209MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  18% 1.76G/9.95G [00:07<00:37, 218MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  18% 1.79G/9.95G [00:07<00:36, 225MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  18% 1.82G/9.95G [00:08<00:35, 229MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  19% 1.86G/9.95G [00:08<00:35, 230MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  19% 1.89G/9.95G [00:08<00:44, 182MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  19% 1.92G/9.95G [00:08<00:40, 197MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  20% 1.95G/9.95G [00:08<00:38, 209MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  20% 1.98G/9.95G [00:08<00:37, 215MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  20% 2.01G/9.95G [00:08<00:35, 221MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  21% 2.04G/9.95G [00:09<00:34, 230MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  21% 2.08G/9.95G [00:09<00:33, 232MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  21% 2.11G/9.95G [00:09<00:43, 182MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  22% 2.14G/9.95G [00:09<00:39, 196MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  22% 2.17G/9.95G [00:09<00:40, 194MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  22% 2.20G/9.95G [00:09<00:37, 205MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  22% 2.23G/9.95G [00:10<00:36, 214MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  23% 2.26G/9.95G [00:10<00:35, 219MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  23% 2.30G/9.95G [00:10<00:33, 227MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  23% 2.33G/9.95G [00:10<00:39, 192MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  24% 2.36G/9.95G [00:10<00:36, 208MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  24% 2.39G/9.95G [00:10<00:35, 215MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  24% 2.42G/9.95G [00:10<00:33, 224MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  25% 2.45G/9.95G [00:11<00:32, 230MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  25% 2.49G/9.95G [00:11<00:31, 235MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  25% 2.52G/9.95G [00:11<00:41, 180MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  26% 2.55G/9.95G [00:11<00:38, 193MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  26% 2.58G/9.95G [00:11<00:36, 205MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  26% 2.61G/9.95G [00:11<00:34, 214MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  27% 2.64G/9.95G [00:11<00:33, 219MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  27% 2.67G/9.95G [00:12<00:32, 227MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  27% 2.71G/9.95G [00:12<00:31, 232MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  28% 2.74G/9.95G [00:12<00:38, 185MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  28% 2.77G/9.95G [00:12<00:36, 199MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  28% 2.80G/9.95G [00:12<00:33, 211MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  28% 2.83G/9.95G [00:12<00:32, 220MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  29% 2.86G/9.95G [00:12<00:31, 225MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  29% 2.89G/9.95G [00:13<00:30, 231MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  29% 2.93G/9.95G [00:13<00:30, 234MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  30% 2.96G/9.95G [00:13<00:38, 181MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  30% 2.99G/9.95G [00:13<00:35, 195MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  30% 3.02G/9.95G [00:13<00:33, 205MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  31% 3.05G/9.95G [00:13<00:32, 215MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  31% 3.08G/9.95G [00:14<00:30, 222MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  31% 3.11G/9.95G [00:14<00:29, 232MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  32% 3.15G/9.95G [00:14<00:37, 180MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  32% 3.18G/9.95G [00:14<00:34, 196MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  32% 3.21G/9.95G [00:14<00:32, 208MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  33% 3.24G/9.95G [00:14<00:31, 213MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  33% 3.27G/9.95G [00:14<00:30, 218MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  33% 3.30G/9.95G [00:15<00:29, 228MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  34% 3.33G/9.95G [00:15<00:28, 232MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  34% 3.37G/9.95G [00:15<00:36, 183MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  34% 3.40G/9.95G [00:15<00:33, 197MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  34% 3.43G/9.95G [00:15<00:31, 208MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  35% 3.46G/9.95G [00:15<00:29, 218MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  35% 3.49G/9.95G [00:16<00:29, 221MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  35% 3.52G/9.95G [00:16<00:28, 228MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  36% 3.55G/9.95G [00:16<00:28, 225MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  36% 3.59G/9.95G [00:16<00:34, 185MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  36% 3.62G/9.95G [00:16<00:32, 197MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  37% 3.65G/9.95G [00:16<00:30, 210MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  37% 3.68G/9.95G [00:16<00:28, 220MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  37% 3.71G/9.95G [00:17<00:40, 156MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  38% 3.74G/9.95G [00:17<00:35, 177MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  38% 3.77G/9.95G [00:17<00:31, 195MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  38% 3.81G/9.95G [00:17<00:29, 211MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  39% 3.84G/9.95G [00:17<00:27, 224MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  39% 3.87G/9.95G [00:17<00:26, 228MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  39% 3.90G/9.95G [00:17<00:25, 233MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  40% 3.93G/9.95G [00:18<00:25, 234MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  40% 3.96G/9.95G [00:18<00:25, 236MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  40% 4.00G/9.95G [00:18<00:29, 198MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  40% 4.03G/9.95G [00:18<00:28, 210MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  41% 4.06G/9.95G [00:18<00:26, 218MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  41% 4.09G/9.95G [00:18<00:25, 227MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  41% 4.12G/9.95G [00:18<00:25, 229MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  42% 4.15G/9.95G [00:19<00:24, 234MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  42% 4.18G/9.95G [00:19<00:24, 238MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  42% 4.22G/9.95G [00:19<00:31, 181MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  43% 4.25G/9.95G [00:19<00:28, 197MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  43% 4.28G/9.95G [00:19<00:27, 206MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  43% 4.31G/9.95G [00:19<00:27, 202MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  44% 4.34G/9.95G [00:20<00:26, 213MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  44% 4.37G/9.95G [00:20<00:25, 222MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  44% 4.40G/9.95G [00:20<00:29, 187MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  44% 4.42G/9.95G [00:20<00:29, 190MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  45% 4.45G/9.95G [00:20<00:29, 186MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  45% 4.48G/9.95G [00:20<00:27, 201MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  45% 4.51G/9.95G [00:20<00:25, 215MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  46% 4.54G/9.95G [00:21<00:24, 225MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  46% 4.57G/9.95G [00:21<00:23, 229MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  46% 4.60G/9.95G [00:21<00:22, 233MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  47% 4.63G/9.95G [00:21<00:27, 196MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  47% 4.67G/9.95G [00:21<00:25, 207MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  47% 4.70G/9.95G [00:21<00:24, 217MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  48% 4.73G/9.95G [00:21<00:23, 226MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  48% 4.76G/9.95G [00:22<00:22, 231MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  48% 4.79G/9.95G [00:22<00:21, 235MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  48% 4.82G/9.95G [00:22<00:28, 181MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  49% 4.85G/9.95G [00:22<00:25, 199MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  49% 4.89G/9.95G [00:22<00:24, 205MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  49% 4.92G/9.95G [00:22<00:23, 211MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  50% 4.95G/9.95G [00:22<00:22, 224MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  50% 4.98G/9.95G [00:23<00:21, 232MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  50% 5.01G/9.95G [00:23<00:20, 237MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  51% 5.04G/9.95G [00:23<00:26, 183MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  51% 5.08G/9.95G [00:23<00:24, 198MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  51% 5.11G/9.95G [00:23<00:23, 208MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  52% 5.14G/9.95G [00:23<00:22, 217MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  52% 5.17G/9.95G [00:23<00:21, 223MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  52% 5.20G/9.95G [00:24<00:20, 227MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  53% 5.23G/9.95G [00:24<00:20, 227MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  53% 5.26G/9.95G [00:24<00:25, 180MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  53% 5.30G/9.95G [00:24<00:23, 195MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  54% 5.33G/9.95G [00:24<00:22, 206MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  54% 5.36G/9.95G [00:24<00:21, 217MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  54% 5.39G/9.95G [00:25<00:20, 225MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  54% 5.42G/9.95G [00:25<00:19, 230MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  55% 5.45G/9.95G [00:25<00:24, 181MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  55% 5.48G/9.95G [00:25<00:23, 194MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  55% 5.52G/9.95G [00:25<00:21, 205MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  56% 5.55G/9.95G [00:25<00:20, 217MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  56% 5.58G/9.95G [00:25<00:19, 225MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  56% 5.61G/9.95G [00:26<00:18, 231MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  57% 5.64G/9.95G [00:26<00:18, 236MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  57% 5.67G/9.95G [00:26<00:23, 181MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  57% 5.70G/9.95G [00:26<00:21, 194MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  58% 5.74G/9.95G [00:26<00:20, 205MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  58% 5.77G/9.95G [00:26<00:19, 213MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  58% 5.80G/9.95G [00:27<00:18, 222MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  59% 5.83G/9.95G [00:27<00:18, 227MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  59% 5.86G/9.95G [00:27<00:17, 230MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  59% 5.89G/9.95G [00:27<00:21, 186MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  60% 5.92G/9.95G [00:27<00:20, 201MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  60% 5.96G/9.95G [00:27<00:18, 210MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  60% 5.99G/9.95G [00:27<00:18, 218MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  60% 6.02G/9.95G [00:28<00:17, 225MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  61% 6.05G/9.95G [00:28<00:16, 230MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  61% 6.08G/9.95G [00:28<00:21, 179MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  61% 6.11G/9.95G [00:28<00:19, 194MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  62% 6.14G/9.95G [00:28<00:18, 202MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  62% 6.18G/9.95G [00:28<00:17, 216MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  62% 6.21G/9.95G [00:28<00:16, 226MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  63% 6.24G/9.95G [00:29<00:16, 231MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  63% 6.27G/9.95G [00:29<00:15, 233MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  63% 6.30G/9.95G [00:29<00:20, 181MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  64% 6.33G/9.95G [00:29<00:18, 193MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  64% 6.36G/9.95G [00:29<00:17, 206MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  64% 6.40G/9.95G [00:29<00:16, 214MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  65% 6.43G/9.95G [00:30<00:15, 222MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  65% 6.46G/9.95G [00:30<00:15, 227MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  65% 6.49G/9.95G [00:30<00:15, 230MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  66% 6.52G/9.95G [00:30<00:18, 184MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  66% 6.55G/9.95G [00:30<00:17, 194MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  66% 6.59G/9.95G [00:30<00:16, 203MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  67% 6.62G/9.95G [00:30<00:15, 210MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  67% 6.65G/9.95G [00:31<00:15, 216MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  67% 6.68G/9.95G [00:31<00:14, 222MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  67% 6.71G/9.95G [00:31<00:17, 188MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  68% 6.74G/9.95G [00:31<00:16, 199MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  68% 6.77G/9.95G [00:31<00:15, 210MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  68% 6.81G/9.95G [00:31<00:14, 217MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  69% 6.84G/9.95G [00:31<00:13, 226MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  69% 6.87G/9.95G [00:32<00:13, 232MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  69% 6.90G/9.95G [00:32<00:12, 240MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  70% 6.93G/9.95G [00:32<00:16, 183MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  70% 6.96G/9.95G [00:32<00:15, 196MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  70% 6.99G/9.95G [00:32<00:14, 207MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  71% 7.03G/9.95G [00:32<00:13, 218MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  71% 7.06G/9.95G [00:32<00:12, 227MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  71% 7.09G/9.95G [00:33<00:12, 232MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  72% 7.12G/9.95G [00:33<00:11, 237MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  72% 7.15G/9.95G [00:33<00:16, 174MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  72% 7.18G/9.95G [00:33<00:14, 188MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  73% 7.21G/9.95G [00:33<00:13, 201MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  73% 7.25G/9.95G [00:33<00:12, 211MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  73% 7.28G/9.95G [00:34<00:12, 221MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  73% 7.31G/9.95G [00:34<00:11, 228MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  74% 7.34G/9.95G [00:34<00:13, 187MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  74% 7.37G/9.95G [00:34<00:12, 201MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  74% 7.40G/9.95G [00:34<00:12, 210MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  75% 7.43G/9.95G [00:34<00:11, 216MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  75% 7.47G/9.95G [00:34<00:11, 225MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  75% 7.50G/9.95G [00:35<00:10, 231MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  76% 7.53G/9.95G [00:35<00:10, 235MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  76% 7.56G/9.95G [00:35<00:13, 183MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  76% 7.59G/9.95G [00:35<00:11, 198MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  77% 7.62G/9.95G [00:35<00:11, 206MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  77% 7.65G/9.95G [00:36<00:14, 153MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  77% 7.69G/9.95G [00:36<00:12, 175MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  78% 7.72G/9.95G [00:36<00:11, 193MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  78% 7.75G/9.95G [00:36<00:10, 209MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  78% 7.78G/9.95G [00:36<00:09, 222MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  79% 7.81G/9.95G [00:36<00:09, 232MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  79% 7.84G/9.95G [00:36<00:08, 235MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  79% 7.87G/9.95G [00:36<00:08, 237MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  79% 7.91G/9.95G [00:37<00:08, 238MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  80% 7.94G/9.95G [00:37<00:08, 237MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  80% 7.97G/9.95G [00:37<00:10, 194MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  80% 8.00G/9.95G [00:37<00:09, 206MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  81% 8.03G/9.95G [00:37<00:08, 218MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  81% 8.06G/9.95G [00:37<00:08, 224MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  81% 8.10G/9.95G [00:37<00:08, 227MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  82% 8.13G/9.95G [00:38<00:07, 231MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  82% 8.16G/9.95G [00:38<00:07, 232MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  82% 8.19G/9.95G [00:38<00:09, 183MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  83% 8.22G/9.95G [00:38<00:08, 197MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  83% 8.25G/9.95G [00:38<00:08, 210MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  83% 8.28G/9.95G [00:38<00:07, 218MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  84% 8.32G/9.95G [00:38<00:07, 222MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  84% 8.35G/9.95G [00:39<00:07, 225MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  84% 8.38G/9.95G [00:39<00:06, 229MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  85% 8.41G/9.95G [00:39<00:08, 181MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  85% 8.44G/9.95G [00:39<00:07, 197MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  85% 8.47G/9.95G [00:39<00:07, 209MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  85% 8.50G/9.95G [00:39<00:06, 219MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  86% 8.54G/9.95G [00:40<00:06, 226MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  86% 8.57G/9.95G [00:40<00:05, 232MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  86% 8.60G/9.95G [00:40<00:07, 180MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  87% 8.63G/9.95G [00:40<00:06, 196MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  87% 8.66G/9.95G [00:40<00:06, 208MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  87% 8.69G/9.95G [00:40<00:05, 213MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  88% 8.72G/9.95G [00:40<00:05, 217MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  88% 8.76G/9.95G [00:41<00:05, 228MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  88% 8.79G/9.95G [00:41<00:04, 235MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  89% 8.82G/9.95G [00:41<00:06, 181MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  89% 8.85G/9.95G [00:41<00:05, 191MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  89% 8.88G/9.95G [00:41<00:05, 202MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  90% 8.91G/9.95G [00:41<00:04, 216MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  90% 8.94G/9.95G [00:42<00:04, 222MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  90% 8.98G/9.95G [00:42<00:04, 226MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  91% 9.01G/9.95G [00:42<00:04, 230MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  91% 9.04G/9.95G [00:42<00:04, 187MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  91% 9.07G/9.95G [00:42<00:04, 202MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  91% 9.10G/9.95G [00:42<00:03, 214MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  92% 9.13G/9.95G [00:42<00:03, 222MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  92% 9.16G/9.95G [00:43<00:03, 227MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  92% 9.20G/9.95G [00:43<00:03, 228MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  93% 9.23G/9.95G [00:43<00:04, 179MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  93% 9.26G/9.95G [00:43<00:03, 195MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  93% 9.29G/9.95G [00:43<00:03, 201MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  94% 9.32G/9.95G [00:43<00:03, 197MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  94% 9.35G/9.95G [00:43<00:02, 209MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  94% 9.38G/9.95G [00:44<00:02, 216MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  95% 9.42G/9.95G [00:44<00:02, 222MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  95% 9.45G/9.95G [00:44<00:02, 194MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  95% 9.48G/9.95G [00:44<00:02, 206MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  96% 9.51G/9.95G [00:44<00:02, 216MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  96% 9.54G/9.95G [00:44<00:01, 223MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  96% 9.57G/9.95G [00:45<00:01, 226MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  97% 9.60G/9.95G [00:45<00:01, 229MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  97% 9.64G/9.95G [00:45<00:01, 234MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  97% 9.67G/9.95G [00:45<00:01, 185MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  97% 9.70G/9.95G [00:45<00:01, 199MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  98% 9.73G/9.95G [00:45<00:01, 210MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  98% 9.76G/9.95G [00:45<00:00, 213MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  98% 9.79G/9.95G [00:46<00:00, 224MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  99% 9.83G/9.95G [00:46<00:00, 229MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  99% 9.86G/9.95G [00:46<00:00, 182MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin:  99% 9.89G/9.95G [00:46<00:00, 195MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin: 100% 9.92G/9.95G [00:46<00:00, 208MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00003.bin: 100% 9.95G/9.95G [00:46<00:00, 212MB/s]\n",
            "Downloading shards:  33% 1/3 [00:46<01:33, 46.94s/it]\n",
            "pytorch_model-00002-of-00003.bin:   0% 0.00/9.90G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   0% 31.5M/9.90G [00:00<00:42, 231MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   1% 62.9M/9.90G [00:00<00:40, 242MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   1% 94.4M/9.90G [00:00<00:39, 248MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   1% 126M/9.90G [00:00<00:39, 248MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   2% 157M/9.90G [00:00<00:39, 246MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   2% 189M/9.90G [00:00<00:43, 221MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   2% 220M/9.90G [00:00<00:43, 223MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   3% 252M/9.90G [00:01<00:41, 233MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   3% 283M/9.90G [00:01<00:39, 244MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   3% 315M/9.90G [00:01<00:37, 254MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   3% 346M/9.90G [00:01<00:38, 249MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   4% 377M/9.90G [00:01<00:39, 243MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   4% 409M/9.90G [00:01<00:39, 240MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   4% 440M/9.90G [00:01<00:39, 240MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   5% 472M/9.90G [00:01<00:39, 237MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   5% 503M/9.90G [00:02<00:40, 230MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   5% 535M/9.90G [00:02<00:39, 238MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   6% 566M/9.90G [00:02<00:38, 246MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   6% 598M/9.90G [00:02<00:38, 243MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   6% 629M/9.90G [00:02<00:38, 242MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   7% 661M/9.90G [00:02<00:37, 243MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   7% 692M/9.90G [00:02<00:37, 243MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   7% 724M/9.90G [00:03<00:37, 245MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   8% 755M/9.90G [00:03<00:38, 240MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   8% 786M/9.90G [00:03<00:38, 237MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   8% 818M/9.90G [00:03<00:38, 237MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   9% 849M/9.90G [00:03<00:38, 236MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   9% 881M/9.90G [00:03<00:38, 236MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:   9% 912M/9.90G [00:03<00:38, 236MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  10% 944M/9.90G [00:03<00:37, 237MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  10% 975M/9.90G [00:04<00:37, 235MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  10% 1.01G/9.90G [00:04<00:37, 235MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  10% 1.04G/9.90G [00:04<00:37, 234MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  11% 1.07G/9.90G [00:04<00:39, 221MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  11% 1.10G/9.90G [00:04<00:38, 227MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  11% 1.13G/9.90G [00:04<00:37, 231MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  12% 1.16G/9.90G [00:04<00:36, 237MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  12% 1.20G/9.90G [00:05<00:36, 239MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  12% 1.23G/9.90G [00:05<00:36, 240MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  13% 1.26G/9.90G [00:05<00:46, 185MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  13% 1.29G/9.90G [00:05<00:43, 200MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  13% 1.32G/9.90G [00:05<00:40, 210MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  14% 1.35G/9.90G [00:05<00:39, 218MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  14% 1.38G/9.90G [00:05<00:37, 225MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  14% 1.42G/9.90G [00:06<00:37, 229MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  15% 1.45G/9.90G [00:06<00:36, 229MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  15% 1.48G/9.90G [00:06<00:46, 181MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  15% 1.51G/9.90G [00:06<00:43, 195MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  16% 1.54G/9.90G [00:06<00:40, 206MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  16% 1.57G/9.90G [00:07<00:55, 149MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  16% 1.60G/9.90G [00:07<00:48, 171MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  17% 1.64G/9.90G [00:07<00:43, 190MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  17% 1.67G/9.90G [00:07<00:40, 205MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  17% 1.70G/9.90G [00:07<00:37, 218MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  17% 1.73G/9.90G [00:07<00:35, 227MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  18% 1.76G/9.90G [00:07<00:35, 232MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  18% 1.79G/9.90G [00:07<00:35, 230MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  18% 1.82G/9.90G [00:08<00:35, 230MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  19% 1.86G/9.90G [00:08<00:34, 233MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  19% 1.89G/9.90G [00:08<00:38, 210MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  19% 1.92G/9.90G [00:08<00:38, 210MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  20% 1.95G/9.90G [00:08<00:36, 217MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  20% 1.98G/9.90G [00:08<00:35, 225MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  20% 2.01G/9.90G [00:08<00:33, 235MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  21% 2.04G/9.90G [00:09<00:32, 238MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  21% 2.08G/9.90G [00:09<00:32, 241MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  21% 2.11G/9.90G [00:09<00:41, 186MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  22% 2.14G/9.90G [00:09<00:39, 199MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  22% 2.17G/9.90G [00:09<00:37, 208MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  22% 2.20G/9.90G [00:09<00:35, 217MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  23% 2.23G/9.90G [00:09<00:34, 221MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  23% 2.26G/9.90G [00:10<00:33, 226MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  23% 2.30G/9.90G [00:10<00:33, 230MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  24% 2.33G/9.90G [00:10<00:40, 186MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  24% 2.36G/9.90G [00:10<00:38, 198MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  24% 2.39G/9.90G [00:10<00:38, 196MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  24% 2.41G/9.90G [00:10<00:40, 184MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  25% 2.44G/9.90G [00:11<00:37, 199MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  25% 2.47G/9.90G [00:11<00:35, 210MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  25% 2.51G/9.90G [00:11<00:34, 216MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  26% 2.54G/9.90G [00:11<00:36, 202MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  26% 2.57G/9.90G [00:11<00:34, 211MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  26% 2.60G/9.90G [00:11<00:33, 218MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  27% 2.63G/9.90G [00:11<00:32, 224MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  27% 2.66G/9.90G [00:12<00:31, 230MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  27% 2.69G/9.90G [00:12<00:30, 235MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  28% 2.73G/9.90G [00:12<00:38, 188MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  28% 2.76G/9.90G [00:12<00:35, 203MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  28% 2.79G/9.90G [00:12<00:33, 212MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  28% 2.82G/9.90G [00:12<00:33, 211MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  29% 2.85G/9.90G [00:12<00:31, 221MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  29% 2.88G/9.90G [00:13<00:33, 210MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  29% 2.92G/9.90G [00:13<00:33, 209MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  30% 2.95G/9.90G [00:13<00:35, 195MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  30% 2.98G/9.90G [00:13<00:33, 208MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  30% 3.01G/9.90G [00:13<00:32, 214MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  31% 3.04G/9.90G [00:13<00:31, 218MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  31% 3.07G/9.90G [00:13<00:30, 227MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  31% 3.10G/9.90G [00:14<00:29, 229MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  32% 3.14G/9.90G [00:14<00:29, 231MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  32% 3.17G/9.90G [00:14<00:36, 186MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  32% 3.20G/9.90G [00:14<00:33, 199MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  33% 3.23G/9.90G [00:14<00:31, 211MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  33% 3.26G/9.90G [00:14<00:30, 215MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  33% 3.29G/9.90G [00:15<00:30, 219MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  34% 3.32G/9.90G [00:15<00:29, 221MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  34% 3.36G/9.90G [00:15<00:35, 184MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  34% 3.39G/9.90G [00:15<00:32, 198MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  35% 3.42G/9.90G [00:15<00:30, 211MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  35% 3.45G/9.90G [00:15<00:29, 221MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  35% 3.48G/9.90G [00:15<00:28, 224MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  35% 3.51G/9.90G [00:16<00:27, 230MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  36% 3.54G/9.90G [00:16<00:27, 230MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  36% 3.58G/9.90G [00:16<00:36, 174MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  36% 3.61G/9.90G [00:16<00:32, 193MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  37% 3.64G/9.90G [00:16<00:29, 211MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  37% 3.67G/9.90G [00:16<00:29, 214MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  37% 3.70G/9.90G [00:16<00:28, 220MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  38% 3.73G/9.90G [00:17<00:27, 228MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  38% 3.76G/9.90G [00:17<00:26, 232MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  38% 3.80G/9.90G [00:17<00:32, 186MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  39% 3.83G/9.90G [00:17<00:30, 199MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  39% 3.86G/9.90G [00:17<00:28, 209MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  39% 3.89G/9.90G [00:17<00:27, 219MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  40% 3.92G/9.90G [00:18<00:26, 226MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  40% 3.95G/9.90G [00:18<00:25, 232MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  40% 3.98G/9.90G [00:18<00:32, 180MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  41% 4.02G/9.90G [00:18<00:30, 195MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  41% 4.05G/9.90G [00:18<00:28, 208MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  41% 4.08G/9.90G [00:18<00:26, 217MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  42% 4.11G/9.90G [00:18<00:26, 223MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  42% 4.14G/9.90G [00:19<00:25, 223MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  42% 4.17G/9.90G [00:19<00:24, 230MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  42% 4.20G/9.90G [00:19<00:31, 183MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  43% 4.24G/9.90G [00:19<00:29, 195MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  43% 4.27G/9.90G [00:19<00:27, 205MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  43% 4.30G/9.90G [00:19<00:26, 213MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  44% 4.33G/9.90G [00:19<00:25, 221MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  44% 4.36G/9.90G [00:20<00:24, 226MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  44% 4.39G/9.90G [00:20<00:23, 234MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  45% 4.42G/9.90G [00:20<00:29, 187MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  45% 4.46G/9.90G [00:20<00:27, 200MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  45% 4.49G/9.90G [00:20<00:26, 208MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  46% 4.52G/9.90G [00:20<00:25, 212MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  46% 4.55G/9.90G [00:21<00:26, 205MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  46% 4.58G/9.90G [00:21<00:25, 205MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  47% 4.61G/9.90G [00:21<00:27, 191MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  47% 4.65G/9.90G [00:21<00:25, 204MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  47% 4.68G/9.90G [00:21<00:24, 211MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  48% 4.71G/9.90G [00:21<00:24, 216MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  48% 4.74G/9.90G [00:21<00:23, 221MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  48% 4.77G/9.90G [00:22<00:25, 204MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  48% 4.80G/9.90G [00:22<00:23, 217MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  49% 4.83G/9.90G [00:22<00:26, 194MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  49% 4.87G/9.90G [00:22<00:24, 206MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  49% 4.90G/9.90G [00:22<00:23, 214MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  50% 4.93G/9.90G [00:22<00:22, 219MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  50% 4.96G/9.90G [00:22<00:22, 223MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  50% 4.99G/9.90G [00:23<00:21, 227MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  51% 5.02G/9.90G [00:23<00:21, 225MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  51% 5.05G/9.90G [00:23<00:25, 190MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  51% 5.09G/9.90G [00:23<00:23, 203MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  52% 5.12G/9.90G [00:23<00:23, 208MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  52% 5.15G/9.90G [00:23<00:22, 216MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  52% 5.18G/9.90G [00:24<00:21, 219MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  53% 5.21G/9.90G [00:24<00:21, 223MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  53% 5.24G/9.90G [00:24<00:25, 185MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  53% 5.27G/9.90G [00:24<00:23, 198MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  54% 5.31G/9.90G [00:24<00:22, 208MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  54% 5.34G/9.90G [00:24<00:21, 216MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  54% 5.37G/9.90G [00:24<00:20, 222MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  55% 5.40G/9.90G [00:25<00:19, 226MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  55% 5.43G/9.90G [00:25<00:19, 229MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  55% 5.46G/9.90G [00:25<00:24, 184MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  55% 5.49G/9.90G [00:25<00:22, 197MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  56% 5.53G/9.90G [00:25<00:20, 211MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  56% 5.56G/9.90G [00:25<00:19, 219MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  56% 5.59G/9.90G [00:25<00:19, 225MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  57% 5.62G/9.90G [00:26<00:18, 230MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  57% 5.65G/9.90G [00:26<00:18, 234MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  57% 5.68G/9.90G [00:26<00:23, 183MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  58% 5.71G/9.90G [00:26<00:21, 198MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  58% 5.75G/9.90G [00:26<00:19, 211MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  58% 5.78G/9.90G [00:26<00:20, 201MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  59% 5.81G/9.90G [00:27<00:19, 209MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  59% 5.84G/9.90G [00:27<00:18, 217MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  59% 5.87G/9.90G [00:27<00:21, 188MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  60% 5.90G/9.90G [00:27<00:20, 200MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  60% 5.93G/9.90G [00:27<00:18, 210MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  60% 5.97G/9.90G [00:27<00:18, 217MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  61% 6.00G/9.90G [00:27<00:17, 223MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  61% 6.03G/9.90G [00:28<00:16, 229MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  61% 6.06G/9.90G [00:28<00:16, 230MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  62% 6.09G/9.90G [00:28<00:20, 185MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  62% 6.12G/9.90G [00:28<00:19, 197MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  62% 6.16G/9.90G [00:28<00:18, 208MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  62% 6.19G/9.90G [00:28<00:17, 216MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  63% 6.22G/9.90G [00:28<00:16, 225MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  63% 6.25G/9.90G [00:29<00:15, 230MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  63% 6.28G/9.90G [00:29<00:15, 228MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  64% 6.31G/9.90G [00:29<00:19, 181MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  64% 6.34G/9.90G [00:29<00:18, 196MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  64% 6.38G/9.90G [00:29<00:17, 206MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  65% 6.41G/9.90G [00:29<00:16, 215MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  65% 6.44G/9.90G [00:30<00:15, 223MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  65% 6.47G/9.90G [00:30<00:14, 231MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  66% 6.50G/9.90G [00:30<00:18, 183MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  66% 6.53G/9.90G [00:30<00:17, 196MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  66% 6.56G/9.90G [00:30<00:16, 208MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  67% 6.60G/9.90G [00:30<00:15, 215MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  67% 6.63G/9.90G [00:30<00:14, 222MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  67% 6.66G/9.90G [00:31<00:14, 227MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  68% 6.69G/9.90G [00:31<00:14, 226MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  68% 6.72G/9.90G [00:31<00:17, 186MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  68% 6.75G/9.90G [00:31<00:15, 199MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  68% 6.78G/9.90G [00:31<00:14, 211MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  69% 6.82G/9.90G [00:31<00:13, 222MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  69% 6.85G/9.90G [00:31<00:13, 228MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  69% 6.88G/9.90G [00:32<00:13, 230MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  70% 6.91G/9.90G [00:32<00:12, 237MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  70% 6.94G/9.90G [00:32<00:16, 179MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  70% 6.97G/9.90G [00:32<00:15, 193MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  71% 7.00G/9.90G [00:32<00:14, 206MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  71% 7.04G/9.90G [00:32<00:13, 217MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  71% 7.07G/9.90G [00:33<00:12, 228MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  72% 7.10G/9.90G [00:33<00:12, 230MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  72% 7.13G/9.90G [00:33<00:15, 179MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  72% 7.16G/9.90G [00:33<00:13, 196MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  73% 7.19G/9.90G [00:33<00:12, 209MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  73% 7.22G/9.90G [00:33<00:12, 222MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  73% 7.26G/9.90G [00:33<00:11, 234MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  74% 7.29G/9.90G [00:34<00:11, 238MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  74% 7.32G/9.90G [00:34<00:10, 246MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  74% 7.35G/9.90G [00:34<00:14, 173MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  75% 7.38G/9.90G [00:34<00:13, 190MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  75% 7.41G/9.90G [00:34<00:12, 202MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  75% 7.44G/9.90G [00:34<00:11, 210MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  75% 7.48G/9.90G [00:34<00:11, 219MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  76% 7.51G/9.90G [00:35<00:10, 228MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  76% 7.54G/9.90G [00:35<00:10, 226MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  76% 7.57G/9.90G [00:35<00:12, 182MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  77% 7.60G/9.90G [00:35<00:11, 197MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  77% 7.63G/9.90G [00:35<00:11, 204MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  77% 7.67G/9.90G [00:35<00:10, 214MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  78% 7.70G/9.90G [00:36<00:09, 221MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  78% 7.73G/9.90G [00:36<00:09, 225MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  78% 7.76G/9.90G [00:36<00:11, 183MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  79% 7.79G/9.90G [00:36<00:10, 195MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  79% 7.82G/9.90G [00:36<00:10, 205MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  79% 7.85G/9.90G [00:36<00:09, 215MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  80% 7.89G/9.90G [00:36<00:09, 222MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  80% 7.92G/9.90G [00:37<00:08, 226MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  80% 7.95G/9.90G [00:37<00:08, 229MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  81% 7.98G/9.90G [00:37<00:10, 182MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  81% 8.00G/9.90G [00:37<00:10, 185MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  81% 8.03G/9.90G [00:37<00:09, 196MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  81% 8.06G/9.90G [00:37<00:08, 209MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  82% 8.10G/9.90G [00:37<00:08, 221MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  82% 8.13G/9.90G [00:38<00:07, 225MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  82% 8.16G/9.90G [00:38<00:07, 227MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  83% 8.19G/9.90G [00:38<00:08, 193MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  83% 8.22G/9.90G [00:38<00:08, 205MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  83% 8.25G/9.90G [00:38<00:07, 216MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  84% 8.28G/9.90G [00:38<00:07, 225MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  84% 8.32G/9.90G [00:38<00:06, 228MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  84% 8.35G/9.90G [00:39<00:06, 232MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  85% 8.38G/9.90G [00:39<00:06, 239MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  85% 8.41G/9.90G [00:39<00:08, 182MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  85% 8.44G/9.90G [00:39<00:07, 197MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  86% 8.47G/9.90G [00:39<00:06, 207MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  86% 8.50G/9.90G [00:39<00:06, 213MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  86% 8.54G/9.90G [00:40<00:06, 219MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  86% 8.57G/9.90G [00:40<00:05, 228MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  87% 8.60G/9.90G [00:40<00:07, 182MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  87% 8.63G/9.90G [00:40<00:06, 197MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  87% 8.66G/9.90G [00:40<00:06, 207MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  88% 8.69G/9.90G [00:40<00:05, 216MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  88% 8.72G/9.90G [00:40<00:05, 223MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  88% 8.76G/9.90G [00:41<00:05, 228MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  89% 8.79G/9.90G [00:41<00:04, 229MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  89% 8.82G/9.90G [00:41<00:05, 182MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  89% 8.84G/9.90G [00:41<00:05, 179MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  89% 8.86G/9.90G [00:41<00:05, 184MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  90% 8.89G/9.90G [00:41<00:05, 199MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  90% 8.92G/9.90G [00:41<00:04, 211MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  90% 8.95G/9.90G [00:42<00:04, 219MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  91% 8.99G/9.90G [00:42<00:04, 224MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  91% 9.02G/9.90G [00:42<00:04, 199MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  91% 9.05G/9.90G [00:42<00:04, 209MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  92% 9.08G/9.90G [00:42<00:03, 217MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  92% 9.11G/9.90G [00:42<00:03, 226MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  92% 9.14G/9.90G [00:42<00:03, 231MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  93% 9.18G/9.90G [00:43<00:03, 232MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  93% 9.21G/9.90G [00:43<00:02, 234MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  93% 9.24G/9.90G [00:43<00:04, 162MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  94% 9.27G/9.90G [00:43<00:03, 184MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  94% 9.30G/9.90G [00:43<00:02, 204MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  94% 9.33G/9.90G [00:43<00:02, 215MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  95% 9.36G/9.90G [00:44<00:02, 220MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  95% 9.40G/9.90G [00:44<00:02, 226MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  95% 9.43G/9.90G [00:44<00:02, 230MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  95% 9.46G/9.90G [00:44<00:02, 196MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  96% 9.49G/9.90G [00:44<00:02, 207MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  96% 9.52G/9.90G [00:44<00:01, 218MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  96% 9.55G/9.90G [00:44<00:01, 224MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  97% 9.58G/9.90G [00:45<00:01, 232MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  97% 9.62G/9.90G [00:45<00:01, 235MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  97% 9.65G/9.90G [00:45<00:01, 182MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  98% 9.68G/9.90G [00:45<00:01, 196MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  98% 9.71G/9.90G [00:45<00:00, 209MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  98% 9.74G/9.90G [00:45<00:00, 217MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  99% 9.77G/9.90G [00:45<00:00, 221MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  99% 9.80G/9.90G [00:46<00:00, 230MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin:  99% 9.84G/9.90G [00:46<00:00, 230MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin: 100% 9.87G/9.90G [00:46<00:00, 183MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00003.bin: 100% 9.90G/9.90G [00:46<00:00, 212MB/s]\n",
            "Downloading shards:  67% 2/3 [01:33<00:46, 46.86s/it]\n",
            "pytorch_model-00003-of-00003.bin:   0% 0.00/6.24G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   0% 21.0M/6.24G [00:00<00:34, 181MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   1% 41.9M/6.24G [00:00<00:33, 185MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   1% 62.9M/6.24G [00:00<00:31, 195MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   2% 94.4M/6.24G [00:00<00:28, 217MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   2% 126M/6.24G [00:00<00:25, 239MB/s] \u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   3% 157M/6.24G [00:00<00:24, 244MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   3% 189M/6.24G [00:00<00:24, 245MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   4% 220M/6.24G [00:00<00:24, 249MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   4% 252M/6.24G [00:01<00:24, 241MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   5% 283M/6.24G [00:01<00:25, 234MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   5% 315M/6.24G [00:01<00:24, 244MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   6% 346M/6.24G [00:01<00:24, 244MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   6% 377M/6.24G [00:01<00:23, 245MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   7% 409M/6.24G [00:01<00:23, 246MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   7% 440M/6.24G [00:01<00:23, 247MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   8% 472M/6.24G [00:01<00:23, 246MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   8% 503M/6.24G [00:02<00:23, 244MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   9% 535M/6.24G [00:02<00:24, 238MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   9% 566M/6.24G [00:02<00:23, 238MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  10% 598M/6.24G [00:02<00:23, 243MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  10% 629M/6.24G [00:02<00:23, 240MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  11% 661M/6.24G [00:02<00:22, 243MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  11% 692M/6.24G [00:02<00:22, 242MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  12% 724M/6.24G [00:03<00:22, 241MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  12% 755M/6.24G [00:03<00:22, 243MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  13% 786M/6.24G [00:03<00:22, 240MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  13% 818M/6.24G [00:03<00:22, 242MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  14% 849M/6.24G [00:03<00:29, 184MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  14% 881M/6.24G [00:03<00:26, 199MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  15% 912M/6.24G [00:03<00:25, 208MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  15% 944M/6.24G [00:04<00:24, 215MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  16% 975M/6.24G [00:04<00:23, 222MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  16% 1.01G/6.24G [00:04<00:22, 228MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  17% 1.04G/6.24G [00:04<00:22, 234MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  17% 1.07G/6.24G [00:04<00:28, 183MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  18% 1.10G/6.24G [00:04<00:26, 196MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  18% 1.13G/6.24G [00:04<00:24, 211MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  19% 1.16G/6.24G [00:05<00:23, 217MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  19% 1.20G/6.24G [00:05<00:22, 225MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  20% 1.23G/6.24G [00:05<00:21, 231MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  20% 1.26G/6.24G [00:05<00:27, 180MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  21% 1.29G/6.24G [00:05<00:25, 193MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  21% 1.32G/6.24G [00:05<00:23, 206MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  22% 1.35G/6.24G [00:06<00:22, 220MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  22% 1.38G/6.24G [00:06<00:20, 232MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  23% 1.42G/6.24G [00:06<00:20, 236MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  23% 1.45G/6.24G [00:06<00:19, 240MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  24% 1.48G/6.24G [00:06<00:26, 178MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  24% 1.50G/6.24G [00:06<00:36, 131MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  25% 1.53G/6.24G [00:07<00:30, 156MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  25% 1.56G/6.24G [00:07<00:26, 175MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  26% 1.59G/6.24G [00:07<00:23, 194MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  26% 1.63G/6.24G [00:07<00:21, 210MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  27% 1.66G/6.24G [00:07<00:20, 222MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  27% 1.69G/6.24G [00:07<00:19, 232MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  28% 1.72G/6.24G [00:07<00:19, 236MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  28% 1.75G/6.24G [00:07<00:18, 236MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  29% 1.78G/6.24G [00:08<00:19, 235MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  29% 1.81G/6.24G [00:08<00:18, 237MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  30% 1.85G/6.24G [00:08<00:18, 236MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  30% 1.88G/6.24G [00:08<00:18, 231MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  31% 1.91G/6.24G [00:08<00:21, 203MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  31% 1.94G/6.24G [00:08<00:20, 211MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  32% 1.97G/6.24G [00:08<00:19, 222MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  32% 2.00G/6.24G [00:09<00:18, 224MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  33% 2.03G/6.24G [00:09<00:18, 227MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  33% 2.07G/6.24G [00:09<00:18, 229MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  34% 2.10G/6.24G [00:09<00:22, 188MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  34% 2.13G/6.24G [00:09<00:20, 200MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  35% 2.16G/6.24G [00:09<00:19, 211MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  35% 2.19G/6.24G [00:10<00:18, 216MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  36% 2.22G/6.24G [00:10<00:18, 214MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  36% 2.25G/6.24G [00:10<00:18, 214MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  37% 2.29G/6.24G [00:10<00:17, 226MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  37% 2.32G/6.24G [00:10<00:20, 191MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  38% 2.35G/6.24G [00:10<00:19, 202MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  38% 2.38G/6.24G [00:10<00:18, 208MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  39% 2.41G/6.24G [00:11<00:17, 217MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  39% 2.44G/6.24G [00:11<00:16, 226MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  40% 2.47G/6.24G [00:11<00:16, 232MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  40% 2.51G/6.24G [00:11<00:16, 231MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  41% 2.54G/6.24G [00:11<00:19, 186MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  41% 2.57G/6.24G [00:11<00:18, 196MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  42% 2.60G/6.24G [00:12<00:17, 204MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  42% 2.63G/6.24G [00:12<00:19, 182MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  43% 2.65G/6.24G [00:12<00:19, 182MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  43% 2.68G/6.24G [00:12<00:17, 198MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  44% 2.72G/6.24G [00:12<00:17, 205MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  44% 2.75G/6.24G [00:12<00:16, 216MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  45% 2.78G/6.24G [00:12<00:15, 224MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  45% 2.81G/6.24G [00:12<00:15, 228MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  46% 2.84G/6.24G [00:13<00:14, 231MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  46% 2.87G/6.24G [00:13<00:14, 236MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  47% 2.90G/6.24G [00:13<00:13, 240MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  47% 2.94G/6.24G [00:13<00:17, 186MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  48% 2.97G/6.24G [00:13<00:16, 197MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  48% 3.00G/6.24G [00:13<00:15, 210MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  49% 3.03G/6.24G [00:14<00:14, 219MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  49% 3.06G/6.24G [00:14<00:14, 223MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  50% 3.09G/6.24G [00:14<00:13, 227MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  50% 3.12G/6.24G [00:14<00:13, 231MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  51% 3.16G/6.24G [00:14<00:16, 183MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  51% 3.19G/6.24G [00:14<00:15, 195MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  52% 3.22G/6.24G [00:14<00:14, 206MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  52% 3.25G/6.24G [00:15<00:13, 216MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  53% 3.28G/6.24G [00:15<00:13, 218MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  53% 3.31G/6.24G [00:15<00:13, 224MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  54% 3.34G/6.24G [00:15<00:12, 224MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  54% 3.38G/6.24G [00:15<00:15, 185MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  55% 3.41G/6.24G [00:15<00:14, 199MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  55% 3.44G/6.24G [00:16<00:13, 209MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  56% 3.47G/6.24G [00:16<00:12, 217MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  56% 3.50G/6.24G [00:16<00:12, 223MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  57% 3.53G/6.24G [00:16<00:11, 227MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  57% 3.57G/6.24G [00:16<00:14, 185MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  58% 3.60G/6.24G [00:16<00:13, 198MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  58% 3.63G/6.24G [00:16<00:12, 207MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  59% 3.66G/6.24G [00:17<00:12, 214MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  59% 3.69G/6.24G [00:17<00:11, 221MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  60% 3.72G/6.24G [00:17<00:11, 229MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  60% 3.75G/6.24G [00:17<00:10, 230MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  61% 3.79G/6.24G [00:17<00:13, 184MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  61% 3.82G/6.24G [00:17<00:12, 200MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  62% 3.85G/6.24G [00:17<00:11, 208MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  62% 3.88G/6.24G [00:18<00:10, 217MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  63% 3.91G/6.24G [00:18<00:10, 220MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  63% 3.94G/6.24G [00:18<00:10, 224MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  64% 3.97G/6.24G [00:18<00:09, 228MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  64% 4.01G/6.24G [00:18<00:11, 187MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  65% 4.04G/6.24G [00:18<00:10, 201MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  65% 4.07G/6.24G [00:18<00:10, 212MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  66% 4.10G/6.24G [00:19<00:09, 215MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  66% 4.13G/6.24G [00:19<00:09, 221MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  67% 4.16G/6.24G [00:19<00:09, 226MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  67% 4.19G/6.24G [00:19<00:11, 182MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  68% 4.23G/6.24G [00:19<00:10, 193MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  68% 4.26G/6.24G [00:19<00:09, 204MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  69% 4.29G/6.24G [00:20<00:09, 207MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  69% 4.32G/6.24G [00:20<00:12, 152MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  70% 4.35G/6.24G [00:20<00:10, 172MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  70% 4.38G/6.24G [00:20<00:09, 191MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  71% 4.41G/6.24G [00:20<00:08, 210MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  71% 4.45G/6.24G [00:20<00:08, 221MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  72% 4.48G/6.24G [00:21<00:07, 229MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  72% 4.51G/6.24G [00:21<00:07, 230MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  73% 4.54G/6.24G [00:21<00:07, 234MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  73% 4.57G/6.24G [00:21<00:07, 233MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  74% 4.60G/6.24G [00:21<00:07, 231MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  74% 4.63G/6.24G [00:21<00:07, 210MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  75% 4.67G/6.24G [00:21<00:07, 216MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  75% 4.70G/6.24G [00:22<00:06, 223MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  76% 4.73G/6.24G [00:22<00:06, 225MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  76% 4.76G/6.24G [00:22<00:06, 229MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  77% 4.79G/6.24G [00:22<00:06, 216MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  77% 4.82G/6.24G [00:22<00:07, 192MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  78% 4.85G/6.24G [00:22<00:06, 203MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  78% 4.89G/6.24G [00:22<00:06, 212MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  79% 4.92G/6.24G [00:23<00:06, 215MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  79% 4.95G/6.24G [00:23<00:05, 224MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  80% 4.98G/6.24G [00:23<00:05, 226MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  80% 5.01G/6.24G [00:23<00:05, 230MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  81% 5.04G/6.24G [00:23<00:06, 186MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  81% 5.06G/6.24G [00:23<00:06, 189MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  82% 5.10G/6.24G [00:23<00:05, 202MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  82% 5.13G/6.24G [00:24<00:05, 212MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  83% 5.16G/6.24G [00:24<00:04, 224MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  83% 5.19G/6.24G [00:24<00:04, 228MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  84% 5.22G/6.24G [00:24<00:04, 232MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  84% 5.25G/6.24G [00:24<00:05, 188MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  85% 5.28G/6.24G [00:24<00:04, 200MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  85% 5.32G/6.24G [00:24<00:04, 212MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  86% 5.35G/6.24G [00:25<00:04, 218MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  86% 5.38G/6.24G [00:25<00:03, 225MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  87% 5.41G/6.24G [00:25<00:03, 226MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  87% 5.44G/6.24G [00:25<00:03, 229MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  88% 5.47G/6.24G [00:25<00:04, 186MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  88% 5.51G/6.24G [00:25<00:03, 198MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  89% 5.54G/6.24G [00:25<00:03, 210MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  89% 5.57G/6.24G [00:26<00:03, 220MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  90% 5.60G/6.24G [00:26<00:02, 223MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  90% 5.63G/6.24G [00:26<00:02, 223MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  91% 5.66G/6.24G [00:26<00:03, 181MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  91% 5.69G/6.24G [00:26<00:02, 193MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  92% 5.73G/6.24G [00:26<00:02, 204MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  92% 5.76G/6.24G [00:27<00:02, 213MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  93% 5.79G/6.24G [00:27<00:02, 219MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  93% 5.82G/6.24G [00:27<00:01, 227MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  94% 5.85G/6.24G [00:27<00:01, 234MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  94% 5.88G/6.24G [00:27<00:01, 185MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  95% 5.91G/6.24G [00:27<00:01, 199MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  95% 5.95G/6.24G [00:27<00:01, 206MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  96% 5.98G/6.24G [00:28<00:01, 213MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  96% 6.01G/6.24G [00:28<00:01, 221MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  97% 6.04G/6.24G [00:28<00:00, 226MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  97% 6.07G/6.24G [00:28<00:00, 229MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  98% 6.10G/6.24G [00:28<00:00, 185MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  98% 6.13G/6.24G [00:28<00:00, 203MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  99% 6.17G/6.24G [00:28<00:00, 214MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  99% 6.20G/6.24G [00:29<00:00, 222MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin: 100% 6.24G/6.24G [00:29<00:00, 213MB/s]\n",
            "Downloading shards: 100% 3/3 [02:03<00:00, 41.06s/it]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/LLaVA/llava/train/train_mem.py\", line 4, in <module>\n",
            "    train(attn_implementation=\"flash_attention_2\")\n",
            "  File \"/content/LLaVA/llava/train/train.py\", line 827, in train\n",
            "    model = LlavaLlamaForCausalLM.from_pretrained(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 3588, in from_pretrained\n",
            "    config = cls._autoset_attn_implementation(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 1387, in _autoset_attn_implementation\n",
            "    cls._check_and_enable_flash_attn_2(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 1478, in _check_and_enable_flash_attn_2\n",
            "    raise ImportError(f\"{preface} the package flash_attn seems to be not installed. {install_message}\")\n",
            "ImportError: FlashAttention2 has been toggled on, but it cannot be used due to the following error: the package flash_attn seems to be not installed. Please refer to the documentation of https://huggingface.co/docs/transformers/perf_infer_gpu_one#flashattention-2 to install Flash Attention 2.\n",
            "[2025-02-24 17:05:24,602] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 11438\n",
            "[2025-02-24 17:05:24,603] [ERROR] [launch.py:321:sigkill_handler] ['/usr/bin/python3', '-u', 'llava/train/train_mem.py', '--local_rank=0', '--deepspeed', './scripts/zero3.json', '--model_name_or_path', 'liuhaotian/llava-v1.5-13b', '--version', 'v1', '--data_path', './playground/data/llava_v1_5_mix665k.json', '--image_folder', './playground/data', '--vision_tower', 'openai/clip-vit-large-patch14-336', '--mm_projector_type', 'mlp2x_gelu', '--mm_vision_select_layer', '-2', '--mm_use_im_start_end', 'False', '--mm_use_im_patch_token', 'False', '--image_aspect_ratio', 'pad', '--group_by_modality_length', 'True', '--bf16', 'True', '--output_dir', './checkpoints/llava-v1.5-13b-task', '--num_train_epochs', '1', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '50000', '--save_total_limit', '1', '--learning_rate', '2e-5', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32', 'True', '--model_max_length', '2048', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '4', '--lazy_preprocess', 'True', '--report_to', 'wandb'] exits with return code = 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U huggingface_hub"
      ],
      "metadata": {
        "id": "i-6EaZf0QsEW",
        "outputId": "21ac1948-1310-4593-9a5c-67d49ad07e50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.17.3)\n",
            "Collecting huggingface_hub\n",
            "  Downloading huggingface_hub-0.29.1-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.1.31)\n",
            "Downloading huggingface_hub-0.29.1-py3-none-any.whl (468 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.0/468.0 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: huggingface_hub\n",
            "  Attempting uninstall: huggingface_hub\n",
            "    Found existing installation: huggingface-hub 0.17.3\n",
            "    Uninstalling huggingface-hub-0.17.3:\n",
            "      Successfully uninstalled huggingface-hub-0.17.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tokenizers 0.14.1 requires huggingface_hub<0.18,>=0.16.4, but you have huggingface-hub 0.29.1 which is incompatible.\n",
            "llava 1.2.2.post1 requires tokenizers==0.15.1, but you have tokenizers 0.14.1 which is incompatible.\n",
            "llava 1.2.2.post1 requires transformers==4.37.2, but you have transformers 4.34.1 which is incompatible.\n",
            "sentence-transformers 3.4.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.34.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed huggingface_hub-0.29.1\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}